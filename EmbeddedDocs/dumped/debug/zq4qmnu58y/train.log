INFO - 06/04/20 14:50:32 - 0:00:00 - ============ Initialized logger ============
INFO - 06/04/20 14:50:32 - 0:00:00 - adversarial: True
                                     all_langs: ['nl', 'en']
                                     batch_size: 32
                                     cuda: False
                                     device: cpu
                                     dico_build: S2T&T2S
                                     dico_eval: default
                                     dico_max_rank: 15000
                                     dico_max_size: 0
                                     dico_method: csls_knn_10
                                     dico_min_size: 0
                                     dico_threshold: 0
                                     dis_clip_weights: 0
                                     dis_dropout: 0.0
                                     dis_hid_dim: 2048
                                     dis_input_dropout: 0.1
                                     dis_lambda: 1
                                     dis_layers: 2
                                     dis_most_frequent: 0
                                     dis_optimizer: sgd,lr=0.1
                                     dis_smooth: 0.1
                                     dis_steps: 5
                                     emb_dim: 300
                                     epoch_size: 100000
                                     exp_id: 
                                     exp_name: debug
                                     exp_path: C:\Users\xabik\OneDrive\Documents\GitHub\LTP-TopicModel\EmbeddedDocs\dumped\debug\zq4qmnu58y
                                     export: 
                                     lr_decay: 0.98
                                     lr_shrink: 0.5
                                     map_beta: 0.001
                                     map_id_init: True
                                     map_optimizer: sgd,lr=0.1
                                     max_vocab: -1
                                     min_lr: 1e-06
                                     n_epochs: 5
                                     normalize_embeddings: 
                                     seed: -1
                                     src_N: 1
                                     src_embs: ['data/fasttext-vectors/wiki.nl.vec']
                                     src_langs: ['nl']
                                     tgt_emb: data/fasttext-vectors/wiki.en.vec
                                     tgt_lang: en
                                     verbose: 2
INFO - 06/04/20 14:50:32 - 0:00:00 - The experiment will be stored in C:\Users\xabik\OneDrive\Documents\GitHub\LTP-TopicModel\EmbeddedDocs\dumped\debug\zq4qmnu58y
INFO - 06/04/20 14:51:02 - 0:00:30 - collecting all words and their counts
WARNING - 06/04/20 14:51:02 - 0:00:30 - Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.
INFO - 06/04/20 14:51:02 - 0:00:30 - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
INFO - 06/04/20 14:51:03 - 0:00:31 - PROGRESS: at example #10000, processed 7941402 words (8480878/s), 931 word types, 10000 tags
INFO - 06/04/20 14:51:04 - 0:00:32 - PROGRESS: at example #20000, processed 15953830 words (8653844/s), 1414 word types, 20000 tags
INFO - 06/04/20 14:51:05 - 0:00:32 - collected 1589 word types and 24259 unique tags from a corpus of 24259 examples and 19437238 words
INFO - 06/04/20 14:51:05 - 0:00:32 - Loading a fresh vocabulary
INFO - 06/04/20 14:51:05 - 0:00:32 - effective_min_count=1 retains 1589 unique words (100% of original 1589, drops 0)
INFO - 06/04/20 14:51:05 - 0:00:32 - effective_min_count=1 leaves 19437238 word corpus (100% of original 19437238, drops 0)
INFO - 06/04/20 14:51:05 - 0:00:32 - deleting the raw counts dictionary of 1589 items
INFO - 06/04/20 14:51:05 - 0:00:32 - sample=0.001 downsamples 34 most-common words
INFO - 06/04/20 14:51:05 - 0:00:32 - downsampling leaves estimated 4704949 word corpus (24.2% of prior 19437238)
INFO - 06/04/20 14:51:05 - 0:00:32 - estimated required memory for 1589 words and 300 dimensions: 33718900 bytes
INFO - 06/04/20 14:51:05 - 0:00:32 - resetting layer weights
INFO - 06/04/20 14:51:11 - 0:00:38 - training model with 4 workers on 1589 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2
INFO - 06/04/20 14:51:12 - 0:00:39 - EPOCH 1 - PROGRESS: at 12.97% examples, 549964 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:13 - 0:00:40 - EPOCH 1 - PROGRESS: at 25.81% examples, 594413 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:14 - 0:00:41 - EPOCH 1 - PROGRESS: at 39.23% examples, 608172 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:51:15 - 0:00:42 - EPOCH 1 - PROGRESS: at 53.21% examples, 612496 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:51:16 - 0:00:43 - EPOCH 1 - PROGRESS: at 67.75% examples, 611096 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:17 - 0:00:44 - EPOCH 1 - PROGRESS: at 80.11% examples, 619188 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:18 - 0:00:45 - EPOCH 1 - PROGRESS: at 93.17% examples, 622267 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:51:18 - 0:00:46 - job loop exiting, total 2210 jobs
DEBUG - 06/04/20 14:51:18 - 0:00:46 - worker exiting, processed 557 jobs
DEBUG - 06/04/20 14:51:18 - 0:00:46 - worker exiting, processed 559 jobs
INFO - 06/04/20 14:51:18 - 0:00:46 - worker thread finished; awaiting finish of 3 more threads
INFO - 06/04/20 14:51:18 - 0:00:46 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:51:18 - 0:00:46 - worker exiting, processed 547 jobs
INFO - 06/04/20 14:51:18 - 0:00:46 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:51:18 - 0:00:46 - worker exiting, processed 547 jobs
INFO - 06/04/20 14:51:18 - 0:00:46 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:51:18 - 0:00:46 - EPOCH - 1 : training on 19437238 raw words (4704626 effective words) took 7.5s, 623139 effective words/s
INFO - 06/04/20 14:51:19 - 0:00:47 - EPOCH 2 - PROGRESS: at 14.08% examples, 611545 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:20 - 0:00:48 - EPOCH 2 - PROGRESS: at 27.28% examples, 629635 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:51:21 - 0:00:49 - EPOCH 2 - PROGRESS: at 40.70% examples, 633401 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:22 - 0:00:50 - EPOCH 2 - PROGRESS: at 54.76% examples, 629725 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:23 - 0:00:51 - EPOCH 2 - PROGRESS: at 68.68% examples, 618366 words/s, in_qsize 6, out_qsize 1
INFO - 06/04/20 14:51:24 - 0:00:52 - EPOCH 2 - PROGRESS: at 80.17% examples, 619790 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:25 - 0:00:53 - EPOCH 2 - PROGRESS: at 93.45% examples, 624664 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:51:26 - 0:00:54 - job loop exiting, total 2210 jobs
DEBUG - 06/04/20 14:51:26 - 0:00:54 - worker exiting, processed 561 jobs
INFO - 06/04/20 14:51:26 - 0:00:54 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:51:26 - 0:00:54 - worker exiting, processed 554 jobs
INFO - 06/04/20 14:51:26 - 0:00:54 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:51:26 - 0:00:54 - worker exiting, processed 551 jobs
INFO - 06/04/20 14:51:26 - 0:00:54 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:51:26 - 0:00:54 - worker exiting, processed 544 jobs
INFO - 06/04/20 14:51:26 - 0:00:54 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:51:26 - 0:00:54 - EPOCH - 2 : training on 19437238 raw words (4707011 effective words) took 7.5s, 626207 effective words/s
INFO - 06/04/20 14:51:27 - 0:00:55 - EPOCH 3 - PROGRESS: at 14.15% examples, 614402 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:28 - 0:00:56 - EPOCH 3 - PROGRESS: at 27.44% examples, 634135 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:29 - 0:00:57 - EPOCH 3 - PROGRESS: at 41.00% examples, 639265 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:30 - 0:00:58 - EPOCH 3 - PROGRESS: at 55.25% examples, 635712 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:31 - 0:00:59 - EPOCH 3 - PROGRESS: at 69.92% examples, 631140 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:51:32 - 0:01:00 - EPOCH 3 - PROGRESS: at 82.19% examples, 638681 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:33 - 0:01:01 - EPOCH 3 - PROGRESS: at 95.41% examples, 639129 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:51:33 - 0:01:01 - job loop exiting, total 2210 jobs
DEBUG - 06/04/20 14:51:33 - 0:01:01 - worker exiting, processed 549 jobs
INFO - 06/04/20 14:51:33 - 0:01:01 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:51:33 - 0:01:01 - worker exiting, processed 554 jobs
INFO - 06/04/20 14:51:33 - 0:01:01 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:51:33 - 0:01:01 - worker exiting, processed 549 jobs
INFO - 06/04/20 14:51:33 - 0:01:01 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:51:33 - 0:01:01 - worker exiting, processed 558 jobs
INFO - 06/04/20 14:51:33 - 0:01:01 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:51:33 - 0:01:01 - EPOCH - 3 : training on 19437238 raw words (4706965 effective words) took 7.4s, 639411 effective words/s
INFO - 06/04/20 14:51:34 - 0:01:02 - EPOCH 4 - PROGRESS: at 13.98% examples, 609092 words/s, in_qsize 6, out_qsize 1
INFO - 06/04/20 14:51:35 - 0:01:03 - EPOCH 4 - PROGRESS: at 27.02% examples, 624208 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:36 - 0:01:04 - EPOCH 4 - PROGRESS: at 40.56% examples, 632131 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:37 - 0:01:05 - EPOCH 4 - PROGRESS: at 54.52% examples, 626412 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:38 - 0:01:06 - EPOCH 4 - PROGRESS: at 69.00% examples, 622551 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:39 - 0:01:07 - EPOCH 4 - PROGRESS: at 81.25% examples, 630703 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:40 - 0:01:08 - EPOCH 4 - PROGRESS: at 94.51% examples, 633142 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:51:41 - 0:01:08 - job loop exiting, total 2210 jobs
DEBUG - 06/04/20 14:51:41 - 0:01:08 - worker exiting, processed 550 jobs
INFO - 06/04/20 14:51:41 - 0:01:08 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:51:41 - 0:01:08 - worker exiting, processed 546 jobs
INFO - 06/04/20 14:51:41 - 0:01:08 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:51:41 - 0:01:08 - worker exiting, processed 562 jobs
INFO - 06/04/20 14:51:41 - 0:01:08 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:51:41 - 0:01:08 - worker exiting, processed 552 jobs
INFO - 06/04/20 14:51:41 - 0:01:08 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:51:41 - 0:01:08 - EPOCH - 4 : training on 19437238 raw words (4707754 effective words) took 7.4s, 634191 effective words/s
INFO - 06/04/20 14:51:42 - 0:01:09 - EPOCH 5 - PROGRESS: at 14.08% examples, 610551 words/s, in_qsize 7, out_qsize 1
INFO - 06/04/20 14:51:43 - 0:01:10 - EPOCH 5 - PROGRESS: at 27.14% examples, 626589 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:44 - 0:01:11 - EPOCH 5 - PROGRESS: at 40.62% examples, 633104 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:45 - 0:01:12 - EPOCH 5 - PROGRESS: at 54.85% examples, 630430 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:46 - 0:01:13 - EPOCH 5 - PROGRESS: at 69.33% examples, 625655 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:51:47 - 0:01:14 - EPOCH 5 - PROGRESS: at 81.59% examples, 632875 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:48 - 0:01:15 - EPOCH 5 - PROGRESS: at 94.93% examples, 636147 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:51:48 - 0:01:16 - job loop exiting, total 2210 jobs
DEBUG - 06/04/20 14:51:48 - 0:01:16 - worker exiting, processed 546 jobs
INFO - 06/04/20 14:51:48 - 0:01:16 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:51:48 - 0:01:16 - worker exiting, processed 559 jobs
INFO - 06/04/20 14:51:48 - 0:01:16 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:51:48 - 0:01:16 - worker exiting, processed 555 jobs
INFO - 06/04/20 14:51:48 - 0:01:16 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:51:48 - 0:01:16 - worker exiting, processed 550 jobs
INFO - 06/04/20 14:51:48 - 0:01:16 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:51:48 - 0:01:16 - EPOCH - 5 : training on 19437238 raw words (4705150 effective words) took 7.4s, 636269 effective words/s
INFO - 06/04/20 14:51:48 - 0:01:16 - training on a 97186190 raw words (23531506 effective words) took 37.3s, 631148 effective words/s
INFO - 06/04/20 14:51:48 - 0:01:16 - collecting all words and their counts
WARNING - 06/04/20 14:51:48 - 0:01:16 - Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.
INFO - 06/04/20 14:51:48 - 0:01:16 - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
INFO - 06/04/20 14:51:48 - 0:01:16 - PROGRESS: at example #10000, processed 2396065 words (9264519/s), 562 word types, 10000 tags
INFO - 06/04/20 14:51:49 - 0:01:16 - PROGRESS: at example #20000, processed 4921453 words (9312421/s), 736 word types, 20000 tags
INFO - 06/04/20 14:51:49 - 0:01:16 - collected 826 word types and 24137 unique tags from a corpus of 24137 examples and 6035095 words
INFO - 06/04/20 14:51:49 - 0:01:16 - Loading a fresh vocabulary
INFO - 06/04/20 14:51:49 - 0:01:17 - effective_min_count=1 retains 826 unique words (100% of original 826, drops 0)
INFO - 06/04/20 14:51:49 - 0:01:17 - effective_min_count=1 leaves 6035095 word corpus (100% of original 6035095, drops 0)
INFO - 06/04/20 14:51:49 - 0:01:17 - deleting the raw counts dictionary of 826 items
INFO - 06/04/20 14:51:49 - 0:01:17 - sample=0.001 downsamples 36 most-common words
INFO - 06/04/20 14:51:49 - 0:01:17 - downsampling leaves estimated 1474642 word corpus (24.4% of prior 6035095)
INFO - 06/04/20 14:51:49 - 0:01:17 - estimated required memory for 826 words and 300 dimensions: 31359800 bytes
INFO - 06/04/20 14:51:49 - 0:01:17 - resetting layer weights
INFO - 06/04/20 14:51:54 - 0:01:22 - training model with 4 workers on 826 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2
INFO - 06/04/20 14:51:55 - 0:01:23 - EPOCH 1 - PROGRESS: at 21.54% examples, 302844 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:56 - 0:01:24 - EPOCH 1 - PROGRESS: at 43.70% examples, 317966 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:57 - 0:01:25 - EPOCH 1 - PROGRESS: at 67.70% examples, 322923 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:51:58 - 0:01:26 - EPOCH 1 - PROGRESS: at 91.25% examples, 339150 words/s, in_qsize 8, out_qsize 0
DEBUG - 06/04/20 14:51:59 - 0:01:27 - job loop exiting, total 661 jobs
DEBUG - 06/04/20 14:51:59 - 0:01:27 - worker exiting, processed 164 jobs
DEBUG - 06/04/20 14:51:59 - 0:01:27 - worker exiting, processed 160 jobs
DEBUG - 06/04/20 14:51:59 - 0:01:27 - worker exiting, processed 172 jobs
INFO - 06/04/20 14:51:59 - 0:01:27 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:51:59 - 0:01:27 - worker exiting, processed 165 jobs
INFO - 06/04/20 14:51:59 - 0:01:27 - worker thread finished; awaiting finish of 2 more threads
INFO - 06/04/20 14:51:59 - 0:01:27 - worker thread finished; awaiting finish of 1 more threads
INFO - 06/04/20 14:51:59 - 0:01:27 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:51:59 - 0:01:27 - EPOCH - 1 : training on 6035095 raw words (1498804 effective words) took 4.4s, 341619 effective words/s
INFO - 06/04/20 14:52:00 - 0:01:28 - EPOCH 2 - PROGRESS: at 22.69% examples, 319536 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:01 - 0:01:29 - EPOCH 2 - PROGRESS: at 45.38% examples, 328349 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:52:02 - 0:01:30 - EPOCH 2 - PROGRESS: at 69.43% examples, 331683 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:03 - 0:01:31 - EPOCH 2 - PROGRESS: at 92.75% examples, 346079 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:52:03 - 0:01:31 - job loop exiting, total 661 jobs
DEBUG - 06/04/20 14:52:03 - 0:01:31 - worker exiting, processed 168 jobs
INFO - 06/04/20 14:52:03 - 0:01:31 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:52:03 - 0:01:31 - worker exiting, processed 165 jobs
INFO - 06/04/20 14:52:03 - 0:01:31 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:52:03 - 0:01:31 - worker exiting, processed 160 jobs
INFO - 06/04/20 14:52:03 - 0:01:31 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:52:03 - 0:01:31 - worker exiting, processed 168 jobs
INFO - 06/04/20 14:52:03 - 0:01:31 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:52:03 - 0:01:31 - EPOCH - 2 : training on 6035095 raw words (1498675 effective words) took 4.3s, 347413 effective words/s
INFO - 06/04/20 14:52:04 - 0:01:32 - EPOCH 3 - PROGRESS: at 24.26% examples, 345203 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:05 - 0:01:33 - EPOCH 3 - PROGRESS: at 48.18% examples, 348019 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:06 - 0:01:34 - EPOCH 3 - PROGRESS: at 72.01% examples, 344880 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:07 - 0:01:35 - EPOCH 3 - PROGRESS: at 95.07% examples, 355010 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:52:07 - 0:01:35 - job loop exiting, total 661 jobs
DEBUG - 06/04/20 14:52:07 - 0:01:35 - worker exiting, processed 161 jobs
DEBUG - 06/04/20 14:52:07 - 0:01:35 - worker exiting, processed 173 jobs
DEBUG - 06/04/20 14:52:07 - 0:01:35 - worker exiting, processed 162 jobs
INFO - 06/04/20 14:52:07 - 0:01:35 - worker thread finished; awaiting finish of 3 more threads
INFO - 06/04/20 14:52:07 - 0:01:35 - worker thread finished; awaiting finish of 2 more threads
INFO - 06/04/20 14:52:07 - 0:01:35 - worker thread finished; awaiting finish of 1 more threads
DEBUG - 06/04/20 14:52:07 - 0:01:35 - worker exiting, processed 165 jobs
INFO - 06/04/20 14:52:07 - 0:01:35 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:52:07 - 0:01:35 - EPOCH - 3 : training on 6035095 raw words (1498201 effective words) took 4.2s, 355479 effective words/s
INFO - 06/04/20 14:52:08 - 0:01:36 - EPOCH 4 - PROGRESS: at 24.70% examples, 351710 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:09 - 0:01:37 - EPOCH 4 - PROGRESS: at 48.51% examples, 349230 words/s, in_qsize 8, out_qsize 0
INFO - 06/04/20 14:52:10 - 0:01:38 - EPOCH 4 - PROGRESS: at 72.63% examples, 345619 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:11 - 0:01:39 - EPOCH 4 - PROGRESS: at 95.70% examples, 354561 words/s, in_qsize 8, out_qsize 0
DEBUG - 06/04/20 14:52:11 - 0:01:39 - job loop exiting, total 661 jobs
DEBUG - 06/04/20 14:52:12 - 0:01:39 - worker exiting, processed 158 jobs
INFO - 06/04/20 14:52:12 - 0:01:39 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:52:12 - 0:01:39 - worker exiting, processed 165 jobs
DEBUG - 06/04/20 14:52:12 - 0:01:39 - worker exiting, processed 164 jobs
INFO - 06/04/20 14:52:12 - 0:01:39 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:52:12 - 0:01:39 - worker exiting, processed 174 jobs
INFO - 06/04/20 14:52:12 - 0:01:39 - worker thread finished; awaiting finish of 1 more threads
INFO - 06/04/20 14:52:12 - 0:01:39 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:52:12 - 0:01:39 - EPOCH - 4 : training on 6035095 raw words (1497137 effective words) took 4.2s, 355335 effective words/s
INFO - 06/04/20 14:52:13 - 0:01:40 - EPOCH 5 - PROGRESS: at 23.76% examples, 333214 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:14 - 0:01:41 - EPOCH 5 - PROGRESS: at 47.26% examples, 340167 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:15 - 0:01:42 - EPOCH 5 - PROGRESS: at 71.82% examples, 342724 words/s, in_qsize 7, out_qsize 0
INFO - 06/04/20 14:52:16 - 0:01:43 - EPOCH 5 - PROGRESS: at 95.07% examples, 353823 words/s, in_qsize 7, out_qsize 0
DEBUG - 06/04/20 14:52:16 - 0:01:44 - job loop exiting, total 661 jobs
DEBUG - 06/04/20 14:52:16 - 0:01:44 - worker exiting, processed 168 jobs
INFO - 06/04/20 14:52:16 - 0:01:44 - worker thread finished; awaiting finish of 3 more threads
DEBUG - 06/04/20 14:52:16 - 0:01:44 - worker exiting, processed 162 jobs
DEBUG - 06/04/20 14:52:16 - 0:01:44 - worker exiting, processed 170 jobs
INFO - 06/04/20 14:52:16 - 0:01:44 - worker thread finished; awaiting finish of 2 more threads
DEBUG - 06/04/20 14:52:16 - 0:01:44 - worker exiting, processed 161 jobs
INFO - 06/04/20 14:52:16 - 0:01:44 - worker thread finished; awaiting finish of 1 more threads
INFO - 06/04/20 14:52:16 - 0:01:44 - worker thread finished; awaiting finish of 0 more threads
INFO - 06/04/20 14:52:16 - 0:01:44 - EPOCH - 5 : training on 6035095 raw words (1499138 effective words) took 4.2s, 353753 effective words/s
INFO - 06/04/20 14:52:16 - 0:01:44 - training on a 30175475 raw words (7491955 effective words) took 21.4s, 350322 effective words/s
INFO - 06/04/20 14:53:22 - 0:02:50 - ----> MULTILINGUAL ADVERSARIAL TRAINING <----
                                     
                                     
INFO - 06/04/20 14:53:22 - 0:02:50 - Starting adversarial training epoch 0...
INFO - 06/04/20 14:53:23 - 0:02:51 - 000000 - Discriminator loss: 1.3860 - 74 samples/s
INFO - 06/04/20 14:54:55 - 0:04:23 - 004000 - Discriminator loss: 1.3360 - 86 samples/s
INFO - 06/04/20 14:56:28 - 0:05:56 - 008000 - Discriminator loss: 1.3499 - 86 samples/s
INFO - 06/04/20 14:58:01 - 0:07:29 - 012000 - Discriminator loss: 1.3414 - 86 samples/s
INFO - 06/04/20 14:59:35 - 0:09:03 - 016000 - Discriminator loss: 1.3420 - 85 samples/s
INFO - 06/04/20 15:01:12 - 0:10:40 - 020000 - Discriminator loss: 1.3509 - 82 samples/s
INFO - 06/04/20 15:02:51 - 0:12:18 - 024000 - Discriminator loss: 1.3496 - 81 samples/s
INFO - 06/04/20 15:04:31 - 0:13:59 - 028000 - Discriminator loss: 1.3473 - 79 samples/s
INFO - 06/04/20 15:06:12 - 0:15:39 - 032000 - Discriminator loss: 1.3452 - 79 samples/s
INFO - 06/04/20 15:07:53 - 0:17:21 - 036000 - Discriminator loss: 1.3492 - 78 samples/s
INFO - 06/04/20 15:09:35 - 0:19:03 - 040000 - Discriminator loss: 1.3474 - 78 samples/s
INFO - 06/04/20 15:11:18 - 0:20:46 - 044000 - Discriminator loss: 1.3443 - 77 samples/s
INFO - 06/04/20 15:13:03 - 0:22:31 - 048000 - Discriminator loss: 1.3433 - 76 samples/s
INFO - 06/04/20 15:14:47 - 0:24:14 - 052000 - Discriminator loss: 1.3449 - 77 samples/s
INFO - 06/04/20 15:16:31 - 0:25:59 - 056000 - Discriminator loss: 1.3382 - 76 samples/s
INFO - 06/04/20 15:18:15 - 0:27:43 - 060000 - Discriminator loss: 1.3433 - 77 samples/s
INFO - 06/04/20 15:20:00 - 0:29:27 - 064000 - Discriminator loss: 1.3460 - 76 samples/s
INFO - 06/04/20 15:21:45 - 0:31:13 - 068000 - Discriminator loss: 1.3483 - 75 samples/s
INFO - 06/04/20 15:23:29 - 0:32:57 - 072000 - Discriminator loss: 1.3475 - 76 samples/s
INFO - 06/04/20 15:25:13 - 0:34:41 - 076000 - Discriminator loss: 1.3396 - 77 samples/s
INFO - 06/04/20 15:26:57 - 0:36:25 - 080000 - Discriminator loss: 1.3423 - 77 samples/s
INFO - 06/04/20 15:28:40 - 0:38:08 - 084000 - Discriminator loss: 1.3383 - 77 samples/s
INFO - 06/04/20 15:30:23 - 0:39:51 - 088000 - Discriminator loss: 1.3451 - 77 samples/s
INFO - 06/04/20 15:32:05 - 0:41:33 - 092000 - Discriminator loss: 1.3393 - 78 samples/s
INFO - 06/04/20 15:33:47 - 0:43:15 - 096000 - Discriminator loss: 1.3411 - 78 samples/s
INFO - 06/04/20 15:37:48 - 0:47:16 - __log__:{"n_epoch": 0, "purity": 0.054035925620270056}
INFO - 06/04/20 15:37:48 - 0:47:16 - * Best value for "purity": 0.05404
INFO - 06/04/20 15:37:48 - 0:47:16 - * Saving the nl to en mapping to C:\Users\xabik\OneDrive\Documents\GitHub\LTP-TopicModel\EmbeddedDocs\dumped\debug\zq4qmnu58y\best_mapping_nl2en.t7 ...
INFO - 06/04/20 15:37:48 - 0:47:16 - End of epoch 0.
                                     
                                     
INFO - 06/04/20 15:37:48 - 0:47:16 - Decreasing learning rate: 0.10000000 -> 0.09800000
INFO - 06/04/20 15:37:48 - 0:47:16 - Starting adversarial training epoch 1...
INFO - 06/04/20 15:37:49 - 0:47:16 - 000000 - Discriminator loss: 1.3861 - 78 samples/s
INFO - 06/04/20 15:39:29 - 0:48:57 - 004000 - Discriminator loss: 1.3402 - 79 samples/s
INFO - 06/04/20 15:41:11 - 0:50:39 - 008000 - Discriminator loss: 1.3398 - 78 samples/s
INFO - 06/04/20 15:42:54 - 0:52:21 - 012000 - Discriminator loss: 1.3417 - 78 samples/s
INFO - 06/04/20 15:44:35 - 0:54:02 - 016000 - Discriminator loss: 1.3375 - 79 samples/s
INFO - 06/04/20 15:46:16 - 0:55:44 - 020000 - Discriminator loss: 1.3335 - 78 samples/s
INFO - 06/04/20 15:47:58 - 0:57:26 - 024000 - Discriminator loss: 1.3376 - 78 samples/s
INFO - 06/04/20 15:49:39 - 0:59:07 - 028000 - Discriminator loss: 1.3374 - 79 samples/s
INFO - 06/04/20 15:51:21 - 1:00:49 - 032000 - Discriminator loss: 1.3362 - 78 samples/s
INFO - 06/04/20 15:53:03 - 1:02:30 - 036000 - Discriminator loss: 1.3359 - 78 samples/s
INFO - 06/04/20 15:54:44 - 1:04:11 - 040000 - Discriminator loss: 1.3373 - 79 samples/s
INFO - 06/04/20 15:56:25 - 1:05:52 - 044000 - Discriminator loss: 1.3381 - 79 samples/s
INFO - 06/04/20 15:58:06 - 1:07:33 - 048000 - Discriminator loss: 1.3361 - 79 samples/s
INFO - 06/04/20 15:59:46 - 1:09:14 - 052000 - Discriminator loss: 1.3343 - 79 samples/s
INFO - 06/04/20 16:01:27 - 1:10:55 - 056000 - Discriminator loss: 1.3349 - 79 samples/s
INFO - 06/04/20 16:03:09 - 1:12:37 - 060000 - Discriminator loss: 1.3357 - 78 samples/s
INFO - 06/04/20 16:04:50 - 1:14:18 - 064000 - Discriminator loss: 1.3249 - 79 samples/s
INFO - 06/04/20 16:06:37 - 1:16:05 - 068000 - Discriminator loss: 1.3326 - 74 samples/s
INFO - 06/04/20 16:08:23 - 1:17:50 - 072000 - Discriminator loss: 1.3301 - 75 samples/s
INFO - 06/04/20 16:10:03 - 1:19:31 - 076000 - Discriminator loss: 1.3303 - 79 samples/s
INFO - 06/04/20 16:11:45 - 1:21:12 - 080000 - Discriminator loss: 1.3344 - 78 samples/s
INFO - 06/04/20 16:13:25 - 1:22:53 - 084000 - Discriminator loss: 1.3291 - 79 samples/s
INFO - 06/04/20 16:15:04 - 1:24:32 - 088000 - Discriminator loss: 1.3284 - 80 samples/s
INFO - 06/04/20 16:16:45 - 1:26:12 - 092000 - Discriminator loss: 1.3318 - 79 samples/s
INFO - 06/04/20 16:18:24 - 1:27:52 - 096000 - Discriminator loss: 1.3291 - 80 samples/s
INFO - 06/04/20 16:22:21 - 1:31:49 - __log__:{"n_epoch": 1, "purity": 0.054116696809538026}
INFO - 06/04/20 16:22:21 - 1:31:49 - * Best value for "purity": 0.05412
INFO - 06/04/20 16:22:21 - 1:31:49 - * Saving the nl to en mapping to C:\Users\xabik\OneDrive\Documents\GitHub\LTP-TopicModel\EmbeddedDocs\dumped\debug\zq4qmnu58y\best_mapping_nl2en.t7 ...
INFO - 06/04/20 16:22:21 - 1:31:49 - End of epoch 1.
                                     
                                     
INFO - 06/04/20 16:22:21 - 1:31:49 - Decreasing learning rate: 0.09800000 -> 0.09604000
INFO - 06/04/20 16:22:21 - 1:31:49 - Starting adversarial training epoch 2...
INFO - 06/04/20 16:22:22 - 1:31:50 - 000000 - Discriminator loss: 1.2924 - 89 samples/s
INFO - 06/04/20 16:23:59 - 1:33:26 - 004000 - Discriminator loss: 1.3254 - 82 samples/s
INFO - 06/04/20 16:25:37 - 1:35:05 - 008000 - Discriminator loss: 1.3296 - 81 samples/s
INFO - 06/04/20 16:27:16 - 1:36:44 - 012000 - Discriminator loss: 1.3303 - 80 samples/s
INFO - 06/04/20 16:28:55 - 1:38:23 - 016000 - Discriminator loss: 1.3262 - 80 samples/s
INFO - 06/04/20 16:30:34 - 1:40:02 - 020000 - Discriminator loss: 1.3285 - 80 samples/s
INFO - 06/04/20 16:32:14 - 1:41:41 - 024000 - Discriminator loss: 1.3286 - 80 samples/s
INFO - 06/04/20 16:33:53 - 1:43:21 - 028000 - Discriminator loss: 1.3254 - 80 samples/s
INFO - 06/04/20 16:35:38 - 1:45:06 - 032000 - Discriminator loss: 1.3251 - 76 samples/s
INFO - 06/04/20 16:37:30 - 1:46:57 - 036000 - Discriminator loss: 1.3292 - 71 samples/s
INFO - 06/04/20 16:39:14 - 1:48:41 - 040000 - Discriminator loss: 1.3283 - 77 samples/s
INFO - 06/04/20 16:41:18 - 1:50:45 - 044000 - Discriminator loss: 1.3248 - 64 samples/s
INFO - 06/04/20 16:43:10 - 1:52:37 - 048000 - Discriminator loss: 1.3273 - 71 samples/s
INFO - 06/04/20 16:45:04 - 1:54:32 - 052000 - Discriminator loss: 1.3250 - 69 samples/s
INFO - 06/04/20 16:47:01 - 1:56:28 - 056000 - Discriminator loss: 1.3262 - 68 samples/s
INFO - 06/04/20 16:48:57 - 1:58:25 - 060000 - Discriminator loss: 1.3356 - 68 samples/s
INFO - 06/04/20 16:50:49 - 2:00:17 - 064000 - Discriminator loss: 1.3261 - 71 samples/s
INFO - 06/04/20 16:52:39 - 2:02:07 - 068000 - Discriminator loss: 1.3273 - 72 samples/s
INFO - 06/04/20 16:54:22 - 2:03:50 - 072000 - Discriminator loss: 1.3201 - 77 samples/s
INFO - 06/04/20 16:56:07 - 2:05:35 - 076000 - Discriminator loss: 1.3261 - 76 samples/s
INFO - 06/04/20 16:57:53 - 2:07:21 - 080000 - Discriminator loss: 1.3201 - 75 samples/s
INFO - 06/04/20 16:59:38 - 2:09:06 - 084000 - Discriminator loss: 1.3183 - 76 samples/s
INFO - 06/04/20 17:01:30 - 2:10:57 - 088000 - Discriminator loss: 1.3173 - 71 samples/s
INFO - 06/04/20 17:03:11 - 2:12:39 - 092000 - Discriminator loss: 1.3173 - 78 samples/s
INFO - 06/04/20 17:04:54 - 2:14:22 - 096000 - Discriminator loss: 1.3226 - 77 samples/s
INFO - 06/04/20 17:09:20 - 2:18:48 - __log__:{"n_epoch": 2, "purity": 0.053902477568436025}
INFO - 06/04/20 17:09:20 - 2:18:48 - End of epoch 2.
                                     
                                     
INFO - 06/04/20 17:09:20 - 2:18:48 - Decreasing learning rate: 0.09604000 -> 0.09411920
INFO - 06/04/20 17:09:20 - 2:18:48 - Validation metric is smaller than the best: 0.05390 vs 0.05412
INFO - 06/04/20 17:09:20 - 2:18:48 - Starting adversarial training epoch 3...
INFO - 06/04/20 17:09:21 - 2:18:48 - 000000 - Discriminator loss: 1.3011 - 85 samples/s
INFO - 06/04/20 17:11:02 - 2:20:30 - 004000 - Discriminator loss: 1.3244 - 78 samples/s
INFO - 06/04/20 17:12:48 - 2:22:16 - 008000 - Discriminator loss: 1.3244 - 75 samples/s
INFO - 06/04/20 17:14:43 - 2:24:11 - 012000 - Discriminator loss: 1.3202 - 69 samples/s
INFO - 06/04/20 17:16:44 - 2:26:11 - 016000 - Discriminator loss: 1.3228 - 66 samples/s
INFO - 06/04/20 17:18:28 - 2:27:56 - 020000 - Discriminator loss: 1.3186 - 76 samples/s
INFO - 06/04/20 17:20:18 - 2:29:46 - 024000 - Discriminator loss: 1.3217 - 72 samples/s
INFO - 06/04/20 17:22:07 - 2:31:35 - 028000 - Discriminator loss: 1.3206 - 73 samples/s
INFO - 06/04/20 17:24:09 - 2:33:37 - 032000 - Discriminator loss: 1.3208 - 65 samples/s
INFO - 06/04/20 17:26:08 - 2:35:36 - 036000 - Discriminator loss: 1.3177 - 67 samples/s
INFO - 06/04/20 17:28:05 - 2:37:33 - 040000 - Discriminator loss: 1.3157 - 68 samples/s
INFO - 06/04/20 17:30:05 - 2:39:33 - 044000 - Discriminator loss: 1.3233 - 66 samples/s
INFO - 06/04/20 17:32:19 - 2:41:47 - 048000 - Discriminator loss: 1.3208 - 59 samples/s
INFO - 06/04/20 17:34:09 - 2:43:37 - 052000 - Discriminator loss: 1.3235 - 72 samples/s
INFO - 06/04/20 17:35:57 - 2:45:25 - 056000 - Discriminator loss: 1.3221 - 74 samples/s
INFO - 06/04/20 17:37:46 - 2:47:14 - 060000 - Discriminator loss: 1.3149 - 73 samples/s
INFO - 06/04/20 17:39:47 - 2:49:14 - 064000 - Discriminator loss: 1.3194 - 66 samples/s
INFO - 06/04/20 17:41:42 - 2:51:09 - 068000 - Discriminator loss: 1.3178 - 69 samples/s
INFO - 06/04/20 17:43:30 - 2:52:58 - 072000 - Discriminator loss: 1.3168 - 73 samples/s
INFO - 06/04/20 17:45:21 - 2:54:48 - 076000 - Discriminator loss: 1.3159 - 72 samples/s
INFO - 06/04/20 17:47:05 - 2:56:33 - 080000 - Discriminator loss: 1.3177 - 76 samples/s
INFO - 06/04/20 17:49:24 - 2:58:52 - 084000 - Discriminator loss: 1.3156 - 57 samples/s
INFO - 06/04/20 17:51:19 - 3:00:47 - 088000 - Discriminator loss: 1.3225 - 69 samples/s
INFO - 06/04/20 17:53:10 - 3:02:37 - 092000 - Discriminator loss: 1.3202 - 72 samples/s
INFO - 06/04/20 17:54:59 - 3:04:27 - 096000 - Discriminator loss: 1.3181 - 73 samples/s
INFO - 06/04/20 17:59:10 - 3:08:37 - __log__:{"n_epoch": 3, "purity": 0.05401836666608137}
INFO - 06/04/20 17:59:10 - 3:08:37 - End of epoch 3.
                                     
                                     
INFO - 06/04/20 17:59:10 - 3:08:37 - Decreasing learning rate: 0.09411920 -> 0.09223682
INFO - 06/04/20 17:59:10 - 3:08:37 - Validation metric is smaller than the best: 0.05402 vs 0.05412
INFO - 06/04/20 17:59:10 - 3:08:37 - Shrinking the learning rate: 0.09224 -> 0.04612
INFO - 06/04/20 17:59:10 - 3:08:37 - Starting adversarial training epoch 4...
INFO - 06/04/20 17:59:10 - 3:08:38 - 000000 - Discriminator loss: 1.2884 - 84 samples/s
INFO - 06/04/20 18:00:55 - 3:10:23 - 004000 - Discriminator loss: 1.3070 - 76 samples/s
INFO - 06/04/20 18:02:41 - 3:12:09 - 008000 - Discriminator loss: 1.3231 - 75 samples/s
INFO - 06/04/20 18:04:23 - 3:13:50 - 012000 - Discriminator loss: 1.3104 - 78 samples/s
INFO - 06/04/20 18:06:06 - 3:15:33 - 016000 - Discriminator loss: 1.3139 - 77 samples/s
INFO - 06/04/20 18:07:55 - 3:17:23 - 020000 - Discriminator loss: 1.3139 - 72 samples/s
INFO - 06/04/20 18:09:35 - 3:19:03 - 024000 - Discriminator loss: 1.3153 - 80 samples/s
INFO - 06/04/20 18:11:17 - 3:20:45 - 028000 - Discriminator loss: 1.3116 - 78 samples/s
INFO - 06/04/20 18:13:10 - 3:22:37 - 032000 - Discriminator loss: 1.3129 - 71 samples/s
INFO - 06/04/20 18:14:54 - 3:24:22 - 036000 - Discriminator loss: 1.3134 - 76 samples/s
INFO - 06/04/20 18:16:43 - 3:26:10 - 040000 - Discriminator loss: 1.3136 - 73 samples/s
INFO - 06/04/20 18:18:44 - 3:28:12 - 044000 - Discriminator loss: 1.3114 - 65 samples/s
INFO - 06/04/20 18:20:41 - 3:30:09 - 048000 - Discriminator loss: 1.3064 - 68 samples/s
INFO - 06/04/20 18:40:03 - 3:49:31 - 052000 - Discriminator loss: 1.3133 - 6 samples/s
INFO - 06/04/20 18:41:40 - 3:51:08 - 056000 - Discriminator loss: 1.3116 - 82 samples/s
INFO - 06/04/20 18:43:12 - 3:52:40 - 060000 - Discriminator loss: 1.3144 - 86 samples/s
INFO - 06/04/20 18:44:45 - 3:54:12 - 064000 - Discriminator loss: 1.3084 - 86 samples/s
INFO - 06/04/20 18:46:31 - 3:55:59 - 068000 - Discriminator loss: 1.3098 - 74 samples/s
INFO - 06/04/20 18:48:09 - 3:57:37 - 072000 - Discriminator loss: 1.3075 - 82 samples/s
INFO - 06/04/20 18:49:45 - 3:59:13 - 076000 - Discriminator loss: 1.3068 - 83 samples/s
INFO - 06/04/20 18:52:33 - 4:02:01 - 080000 - Discriminator loss: 1.3079 - 47 samples/s
INFO - 06/04/20 18:54:09 - 4:03:36 - 084000 - Discriminator loss: 1.3116 - 84 samples/s
INFO - 06/04/20 18:57:12 - 4:06:40 - 088000 - Discriminator loss: 1.3101 - 43 samples/s
INFO - 06/04/20 19:00:10 - 4:09:38 - 092000 - Discriminator loss: 1.3076 - 44 samples/s
INFO - 06/05/20 11:59:36 - 21:09:04 - 096000 - Discriminator loss: 1.3089 - 0 samples/s
INFO - 06/05/20 12:06:40 - 21:16:07 - __log__:{"n_epoch": 4, "purity": 0.054081578901160644}
INFO - 06/05/20 12:06:40 - 21:16:07 - End of epoch 4.
                                      
                                      
INFO - 06/05/20 12:06:40 - 21:16:07 - Decreasing learning rate: 0.04611841 -> 0.04519604
INFO - 06/05/20 12:06:40 - 21:16:07 - Validation metric is smaller than the best: 0.05408 vs 0.05412
INFO - 06/05/20 12:06:40 - 21:16:07 - Shrinking the learning rate: 0.04520 -> 0.02260
